import torch


def naive_8_bit(embeddings: torch.Tensor, max_val: float) -> torch.Tensor:
    """
    Absolute Maximum Quantization.

    In absolute max quantization, we compute the maximum of the absolute values of all
    elements in the input and normalize the input with it, followed by scaling
    up and rounding to the nearest whole number
    """
    X_q = torch.round(127 / max_val * embeddings)
    X_dq = max_val / 127 * X_q
    return X_dq


def zero_point(embeddings: torch.Tensor, min_val: float, max_val: float) -> torch.Tensor:
    """Zero Point Quantization

    Zero-point quantization is a technique that transforms
    the original floating point range into an 8-bit range (INT8)
    """
    scale = 255 / (max_val - min_val)
    zero_point = -round(scale * min_val) - 128
    X_q = torch.round(scale * embeddings + zero_point)
    X_dq = (X_q - zero_point) / scale
    return X_dq


def quantize(
    embeddings: torch.Tensor, min_val: float, max_val: float, method: str = "naive-8-bit"
) -> torch.Tensor:
    """Quantize embeddings using the specified method."""
    if method == "naive-8-bit":
        return naive_8_bit(embeddings, max_val)
    elif method == "zero_point":
        return zero_point(embeddings, min_val, max_val)
    else:
        return embeddings
